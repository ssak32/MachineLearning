{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Scenario:\n",
    "\n",
    "Recall that almost all of our real world models are supervised. That means we are going to point our model at at dataset. \n",
    "\n",
    "In the exercises to follow we will use a famous data set called the Iris Dataset \n",
    "\n",
    "The data we will use is a very simple flower database known as the Iris dataset.\n",
    "\n",
    "The Iris dataset is composed of 50 samples from three different species of Iris. Each sample contains four features. (What's a feature again?) The length and width of the sepals, the length and width of the pedals. \n",
    "\n",
    "We have 150 observations of the iris flower specifying some measurements: sepal length, sepal width, petal length and petal width together with its subtype: Iris setosa, Iris versicolor, Iris virginica.\n",
    "\n",
    "This data is stored in the .data member, which is a (n_samples, n_features) array.\n",
    "\n",
    "The class of each observation is stored in the .target attribute of the dataset. This is an integer 1D array of length n_samples.\n",
    "\n",
    "To use this dataset with the SciKit-Learn, we transform each 8x8 image into a vector of length 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets   # This is were our Iris dataset is.\n",
    "from sklearn import metrics    # Used to measure/score how our model did.\n",
    "from sklearn.svm import SVC    # Support Vector Machines (SVM) library for modelling (classifying) under Support Vector Classifier (SVC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset onto a variable ds\n",
    "# This dataset is provided as an example dataset with the library and is loaded.\n",
    "ds = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\gitrepositories\\machinelearning\\ml_env\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Fit a SVM model to the data which classifies the data\n",
    "model = SVC()\n",
    "model.fit(ds.data, ds.target)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      0.96      0.98        50\n",
      "           2       0.96      1.00      0.98        50\n",
      "\n",
      "    accuracy                           0.99       150\n",
      "   macro avg       0.99      0.99      0.99       150\n",
      "weighted avg       0.99      0.99      0.99       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "expected = ds.target\n",
    "predicted = model.predict(ds.data)\n",
    "\n",
    "# Summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "Accuracy:\n",
    "Accuracy is perhaps the most intuitive performance measure. It is simply the ratio of correctly predicted observations.  \n",
    "\n",
    "Precision:\n",
    "Precision looks at the ratio of correct positive observations.\n",
    "\n",
    "Recall:\n",
    "Recall is also known as sensitivity or true positive rate. Itâ€™s the ratio of correctly predicted positive events.\n",
    "\n",
    "F1 Score:\n",
    "The F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
